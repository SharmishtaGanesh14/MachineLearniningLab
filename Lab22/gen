# Date created: 20th April 2025

import pandas as pd
import numpy as np
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier


def load_data():
    data=pd.read_csv("../../datasets/Iris.csv")
    X = data.loc[:, ["SepalLengthCm", "SepalWidthCm"]]
    y=data["Species"]
    noise=np.random.normal(0,0.1,size=X.shape)
    X_noisy = X + noise
    X_noisy["SepalLengthCm"]=pd.cut(X["SepalLengthCm"], bins=3, labels=[0, 1, 2])
    X_noisy["SepalWidthCm"]=pd.cut(X["SepalWidthCm"],bins=3,labels=[0,1,2])
    return X_noisy, y

class JointProb:
    def __init__(self,X_train, X_test, y_train, y_test):
        self.X_train=X_train
        self.X_test = X_test
        self.y_train=y_train
        self.y_test = y_test
        self.Table=[]
    def enumerate_possibilities(self):
        X1 = np.unique(self.X_train.iloc[:, 0])
        X2 = np.unique(self.X_train.iloc[:, 1])
        for x in X1:
            for y in X2:
                self.Table.append([x,y])
        print(self.Table)


def evaluation(model,X_train,X_test,y_train,y_test,l):
    model.fit(X_train,y_train)
    y_pred=model.predict(X_test)
    print("Evaluation metrics:\n",classification_report(y_test, y_pred, output_dict=False, target_names=l.classes_))

def main():
    X,y=load_data()
    X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=532,stratify=y)
    label = LabelEncoder()
    y_train=label.fit_transform(y_train)
    y_test=label.transform(y_test)

    # Model 1 - Decision tree classifier
    print(f"Decision Tree Classifier")
    model=DecisionTreeClassifier(max_depth=2)
    evaluation(model,X_train, X_test, y_train, y_test,label)

    # Model 2 - Simple Joint probability distribution
    print("Simple Joint probability distribution")
    model=JointProb(X_train, X_test, y_train, y_test)

    model.enumerate_possibilities()
if __name__=="__main__":
    main()
